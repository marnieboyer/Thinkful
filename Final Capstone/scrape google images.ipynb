{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code will run google search images and save the photos to my hard drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#credit https://github.com/hardikvasa/google-images-download/blob/master/google-images-download.py\n",
    "# I made changes for Python 3 and to accomodate my settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import time       #Importing the time library to check the time of code execution\n",
    "import sys    #Importing the System Library\n",
    "import os\n",
    "#import urllib2\n",
    "import urllib.request    #urllib library for Extracting web pages\n",
    "\n",
    "########### Edit From Here ###########\n",
    "\n",
    "#This list is used to search keywords. You can edit this list to search for google images of your choice. \n",
    "#You can simply add and remove elements of the list.\n",
    "\n",
    "search_keyword =  ['Chrissy Teigen']\n",
    "\n",
    "# 'women with round face shapes','women with oval face shapes','women with long face shapes',\n",
    "                  #'women with heart face shapes','women with square face shapes'   \n",
    "\n",
    "\n",
    "#round faces\n",
    "#search_keyword = ['Adele','kate bosworth','Kate Upton','kelly clarkson','olivia munn',\n",
    " #                 'Selena Gomez','hayden panettiere','Jennifer Hudson','Kaley Cuoco','Sarah Hyland']\n",
    "                  #  'kirsten dunst','Ginnifer Goodwin','kelly osbourne','mila kunis','christina ricci',\n",
    "               #   'drew barrymore',\n",
    "\n",
    "# heart faces:\n",
    "#search_keyword = ['reese witherspoon', 'Scarlett Johansson','Eva Longoria','taylor swift',\n",
    " #                 'Ashley Greene','Naomi Campbell','julianne hough','katharine mcphee']\n",
    "#'brittany snow','Cheryl Cole','ciara','heather graham','Jennifer Love Hewitt','Kourtney Kardashian','Mary-Kate Olsen'\n",
    "\n",
    "    \n",
    "#   SQUARE:\n",
    "#search_keyword = ['Gwyneth Paltrow','Rosario Dawson','kate Middleton','Lucy Liu','Nicole Richie',\n",
    " #                 'Rachel McAdams','Claire Danes','Lea Michele','Billie Piper','Diane Kruger','Emily Deschanel',\n",
    "  #                'Isabella Rosselini','Lily Aldridge','Paris Hilton','Denise Richards']\n",
    "\n",
    "\n",
    "# LONG faces:\n",
    "#search_keyword = ['Liv Tyler','sarah jessica parker','Gisele Bundchen','Salma Hayek','Lisa Kudrow',                  \n",
    "              #    'Megan Fox','adrianne palicki','arizona muse','Ashlee Simpson','Milla Jovovich','Teri Hatcher']\n",
    "  #  ['Tyra Banks','Christa B Allen','Hilary Swank','Olivia Newton John','Rose Byrne']\n",
    "\n",
    "\n",
    "#OVAL faces:\n",
    "#['Emma Watson','eva mendes','jessica biel','Blake Lively','katy perry','Kim Kardashian','Zooey Deschanel']\n",
    "#other ovals: 'jessica alba','Rihanna','beyonce knowles','Jennifer Aniston','Charlize Theron'\n",
    "\n",
    "\n",
    "#This list is used to further add suffix to your search term. Each element of the list will help you download 100 images. \n",
    "#First element is blank which denotes that no suffix is added to the search keyword of the above list. \n",
    "#You can edit the list by adding/deleting elements from it.So if the first element of the search_keyword is \n",
    "#'Australia' and the second element of keywords is 'high resolution', then it will search for 'Australia High Resolution'\n",
    "keywords = [' face']\n",
    "\n",
    "########### End of Editing ###########\n",
    "\n",
    "#Downloading entire Web Document (Raw Page Content)\n",
    "def download_page(url):\n",
    "    #version = (3,0)\n",
    "    #cur_version = sys.version_info\n",
    "    #if cur_version >= version:     #If the Current Version of Python is 3.0 or above    \n",
    "    try:\n",
    "        headers = {}\n",
    "        headers['User-Agent'] = \"Mozilla/5.0 (Windows NT 6.1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/41.0.2228.0 Safari/537.36\"\n",
    "        req = urllib.request.Request(url, headers = headers)\n",
    "        resp = urllib.request.urlopen(req)\n",
    "        respData = str(resp.read())\n",
    "        return respData\n",
    "    except Exception as e:\n",
    "        print(str(e))\n",
    "\n",
    "\n",
    "#Finding 'Next Image' from the given raw page\n",
    "def _images_get_next_item(s):\n",
    "    start_line = s.find('rg_di')\n",
    "    if start_line == -1:    #If no links are found then give an error!\n",
    "        end_quote = 0\n",
    "        link = \"no_links\"\n",
    "        return link, end_quote\n",
    "    else:\n",
    "        start_line = s.find('\"class=\"rg_meta\"')\n",
    "        start_content = s.find('\"ou\"',start_line+1)\n",
    "        end_content = s.find(',\"ow\"',start_content+1)\n",
    "        content_raw = str(s[start_content+6:end_content-1])\n",
    "        return content_raw, end_content\n",
    "\n",
    "\n",
    "#Getting all links with the help of '_images_get_next_image'\n",
    "def _images_get_all_items(page):\n",
    "    items = []\n",
    "    while True:\n",
    "        item, end_content = _images_get_next_item(page)\n",
    "        if item == \"no_links\":\n",
    "            break\n",
    "        else:\n",
    "            items.append(item)      #Append all the links in the list named 'Links'\n",
    "            time.sleep(0.1)        #Timer could be used to slow down the request for image downloads\n",
    "            page = page[end_content:]\n",
    "    return items\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Item no.: 1 --> Item name = Chrissy Teigen\n",
      "Evaluating...\n",
      "Total Image Links = 100\n",
      "\n",
      "\n",
      "Total time taken: 12.120000123977661 Seconds\n",
      "Starting Download...\n",
      "completed ====> 1\n",
      "completed ====> 2\n",
      "completed ====> 3\n",
      "completed ====> 4\n",
      "completed ====> 5\n",
      "completed ====> 6\n",
      "IOError on image 7\n",
      "completed ====> 8\n",
      "completed ====> 9\n",
      "completed ====> 10\n",
      "completed ====> 11\n",
      "completed ====> 12\n",
      "completed ====> 13\n",
      "completed ====> 14\n",
      "completed ====> 15\n",
      "completed ====> 16\n",
      "completed ====> 17\n",
      "completed ====> 18\n",
      "completed ====> 19\n",
      "completed ====> 20\n",
      "completed ====> 21\n",
      "completed ====> 22\n",
      "completed ====> 23\n",
      "completed ====> 24\n",
      "completed ====> 25\n",
      "completed ====> 26\n",
      "completed ====> 27\n",
      "completed ====> 28\n",
      "IOError on image 29\n",
      "completed ====> 30\n",
      "completed ====> 31\n",
      "completed ====> 32\n",
      "completed ====> 33\n",
      "completed ====> 34\n",
      "completed ====> 35\n",
      "completed ====> 36\n",
      "completed ====> 37\n",
      "completed ====> 38\n",
      "completed ====> 39\n",
      "completed ====> 40\n",
      "completed ====> 41\n",
      "completed ====> 42\n",
      "completed ====> 43\n",
      "completed ====> 44\n",
      "completed ====> 45\n",
      "completed ====> 46\n",
      "completed ====> 47\n",
      "completed ====> 48\n",
      "completed ====> 49\n",
      "completed ====> 50\n",
      "completed ====> 51\n",
      "completed ====> 52\n",
      "IOError on image 53\n",
      "completed ====> 54\n",
      "completed ====> 55\n",
      "completed ====> 56\n",
      "completed ====> 57\n",
      "completed ====> 58\n",
      "completed ====> 59\n",
      "completed ====> 60\n",
      "completed ====> 61\n",
      "completed ====> 62\n",
      "completed ====> 63\n",
      "IOError on image 64\n",
      "completed ====> 65\n",
      "completed ====> 66\n",
      "completed ====> 67\n",
      "completed ====> 68\n",
      "completed ====> 69\n",
      "completed ====> 70\n",
      "completed ====> 71\n",
      "IOError on image 72\n",
      "completed ====> 73\n",
      "completed ====> 74\n",
      "completed ====> 75\n",
      "completed ====> 76\n",
      "completed ====> 77\n",
      "completed ====> 78\n",
      "completed ====> 79\n",
      "completed ====> 80\n",
      "completed ====> 81\n",
      "completed ====> 82\n",
      "completed ====> 83\n",
      "completed ====> 84\n",
      "completed ====> 85\n",
      "completed ====> 86\n",
      "completed ====> 87\n",
      "completed ====> 88\n",
      "completed ====> 89\n",
      "completed ====> 90\n",
      "completed ====> 91\n",
      "completed ====> 92\n",
      "completed ====> 93\n",
      "completed ====> 94\n",
      "IOError on image 95\n",
      "completed ====> 96\n",
      "completed ====> 97\n",
      "completed ====> 98\n",
      "completed ====> 99\n",
      "completed ====> 100\n",
      "\n",
      "\n",
      "Everything downloaded!\n",
      "\n",
      "6 ----> total Errors\n"
     ]
    }
   ],
   "source": [
    "############## Main Program ############\n",
    "t0 = time.time()   #start the timer\n",
    "\n",
    "#Download Image Links\n",
    "i= 0\n",
    "while i<len(search_keyword):\n",
    "    items = []\n",
    "    iteration = \"Item no.: \" + str(i+1) + \" -->\" + \" Item name = \" + str(search_keyword[i])\n",
    "    print (iteration)\n",
    "    print (\"Evaluating...\")\n",
    "    search_keywords = search_keyword[i]\n",
    "    search = search_keywords.replace(' ','%20')\n",
    "    \n",
    "     #make a search keyword  directory\n",
    "    try:\n",
    "        os.makedirs(search_keywords)\n",
    "    except OSError as e:\n",
    "        if e.errno != 17:\n",
    "            raise   \n",
    "        # time.sleep might help here\n",
    "        pass\n",
    "    \n",
    "    j = 0\n",
    "    while j<len(keywords):\n",
    "        pure_keyword = keywords[j].replace(' ','%20')\n",
    "        url = 'https://www.google.com/search?q=' + search + pure_keyword + '&espv=2&biw=1366&bih=667&site=webhp&source=lnms&tbm=isch&sa=X&ei=XosDVaCXD8TasATItgE&ved=0CAcQ_AUoAg'\n",
    "        raw_html =  (download_page(url))\n",
    "        time.sleep(0.1)\n",
    "        items = items + (_images_get_all_items(raw_html))\n",
    "        j = j + 1\n",
    "    #print (\"Image Links = \"+str(items))\n",
    "    print (\"Total Image Links = \"+str(len(items)))\n",
    "    print (\"\\n\")\n",
    "\n",
    "\n",
    "    #This allows you to write all the links into a test file. This text file will be created in the same directory as your code. You can comment out the below 3 lines to stop writing the output to the text file.\n",
    "    info = open('output.txt', 'a')        #Open the text file called database.txt\n",
    "    info.write(str(i) + ': ' + str(search_keyword[i-1]) + \": \" + str(items) + \"\\n\\n\\n\")         #Write the title of the page\n",
    "    info.close()                            #Close the file\n",
    "\n",
    "    t1 = time.time()    #stop the timer\n",
    "    total_time = t1-t0   #Calculating the total time required to crawl, find and download all the links of 60,000 images\n",
    "    print(\"Total time taken: \"+str(total_time)+\" Seconds\")\n",
    "    print (\"Starting Download...\")\n",
    "\n",
    "    ## To save imges to the same directory\n",
    "    # IN this saving process we are just skipping the URL if there is any error\n",
    "\n",
    "    k=0\n",
    "    errorCount=0\n",
    "    while(k<len(items)):\n",
    "        import urllib.request\n",
    "        from urllib.error import HTTPError\n",
    "        from urllib.error import URLError\n",
    "        from urllib.request import urlopen    #python 3\n",
    "        import urllib.request,urllib.parse,urllib.error    #python 3\n",
    "\n",
    "        try:\n",
    "            req = urllib.request.Request(items[k], headers={\"User-Agent\": \"Mozilla/5.0 (X11; Linux i686) AppleWebKit/537.17 (KHTML, like Gecko) Chrome/24.0.1312.27 Safari/537.17\"})\n",
    "            response = urlopen(req,None,15)\n",
    "            output_file = open(search_keywords+\"/\"+str(k+1)+\".jpg\",'wb')\n",
    "           \n",
    "          \n",
    "            \n",
    "            data = response.read()\n",
    "            output_file.write(data)\n",
    "            response.close();\n",
    "\n",
    "            print(\"completed ====> \"+str(k+1))\n",
    "\n",
    "            k=k+1;\n",
    "\n",
    "        except IOError:   #If there is any IOError\n",
    "\n",
    "            errorCount+=1\n",
    "            print(\"IOError on image \"+str(k+1))\n",
    "            k=k+1;\n",
    "\n",
    "        except urllib.error.HTTPError as e:  #If there is any HTTPError\n",
    "\n",
    "            errorCount+=1\n",
    "            print(\"HTTPError\"+str(k))\n",
    "            k=k+1;\n",
    "        except URLError as e:\n",
    "\n",
    "            errorCount+=1\n",
    "            print(\"URLError \"+str(k))\n",
    "            k=k+1;\n",
    "\n",
    "    i = i+1\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"Everything downloaded!\")\n",
    "print(\"\\n\"+str(errorCount)+\" ----> total Errors\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
